{
    "inference.model": "codellama:7b-code-fp16",
    "inference.custom.format": "codellama"
}